"""
é¡µé¢åˆ†ç±»å™¨è®­ç»ƒè„šæœ¬ - PyTorchç‰ˆæœ¬
æ”¯æŒGPUåŠ é€Ÿã€æ··åˆç²¾åº¦è®­ç»ƒã€è¯¦ç»†è¿›åº¦æ—¥å¿—
"""
import os
import sys
from pathlib import Path
import json
import time
from datetime import datetime, timedelta
import shutil

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
import numpy as np

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))


class PageClassifierDataset(Dataset):
    """é¡µé¢åˆ†ç±»å™¨æ•°æ®é›†"""
    
    def __init__(self, data_dir, transform=None):
        self.data_dir = Path(data_dir)
        self.transform = transform
        self.samples = []
        self.classes = []
        
        # æ‰«ææ‰€æœ‰ç±»åˆ«ç›®å½•
        for class_dir in sorted(self.data_dir.iterdir()):
            if not class_dir.is_dir():
                continue
            
            class_name = class_dir.name
            if class_name not in self.classes:
                self.classes.append(class_name)
            
            class_idx = self.classes.index(class_name)
            
            # æ‰«æè¯¥ç±»åˆ«çš„æ‰€æœ‰å›¾ç‰‡
            for img_path in class_dir.glob("*.png"):
                self.samples.append((str(img_path), class_idx))
        
        print(f"  â€¢ åŠ è½½äº† {len(self.samples)} å¼ å›¾ç‰‡")
        print(f"  â€¢ {len(self.classes)} ä¸ªç±»åˆ«: {', '.join(self.classes[:5])}{'...' if len(self.classes) > 5 else ''}")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        
        # åŠ è½½å›¾ç‰‡
        image = Image.open(img_path).convert('RGB')
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            image = self.transform(image)
        
        return image, label


class PageClassifier(nn.Module):
    """é¡µé¢åˆ†ç±»å™¨æ¨¡å‹ - ä½¿ç”¨MobileNetV2"""
    
    def __init__(self, num_classes):
        super(PageClassifier, self).__init__()
        
        # ä½¿ç”¨MobileNetV2ä½œä¸ºéª¨å¹²ç½‘ç»œ
        self.mobilenet = models.mobilenet_v2(weights=None)
        
        # æ›¿æ¢åˆ†ç±»å™¨
        in_features = self.mobilenet.classifier[1].in_features
        self.mobilenet.classifier = nn.Sequential(
            nn.Dropout(0.2),
            nn.Linear(in_features, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, num_classes)
        )
    
    def forward(self, x):
        return self.mobilenet(x)


def check_gpu_status():
    """æ£€æŸ¥GPUçŠ¶æ€å¹¶ç»™å‡ºä¼˜åŒ–å»ºè®®"""
    if not torch.cuda.is_available():
        print("\nâš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°CUDAæ”¯æŒçš„GPU")
        print("  å»ºè®®:")
        print("  1. æ£€æŸ¥æ˜¯å¦å®‰è£…äº†CUDAç‰ˆæœ¬çš„PyTorch")
        print("  2. è¿è¡Œ: pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118")
        print("  3. ç¡®è®¤æ˜¾å¡é©±åŠ¨å·²æ­£ç¡®å®‰è£…")
        return False
    
    print(f"\nâœ“ GPUå¯ç”¨: {torch.cuda.get_device_name(0)}")
    print(f"  â€¢ CUDAç‰ˆæœ¬: {torch.version.cuda}")
    print(f"  â€¢ æ˜¾å­˜æ€»é‡: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # æµ‹è¯•GPUæ€§èƒ½
    try:
        # åˆ›å»ºæµ‹è¯•å¼ é‡
        test_tensor = torch.randn(1000, 1000).cuda()
        start = time.time()
        for _ in range(100):
            _ = test_tensor @ test_tensor
        torch.cuda.synchronize()
        elapsed = time.time() - start
        print(f"  â€¢ GPUæ€§èƒ½æµ‹è¯•: {elapsed:.3f}ç§’ (100æ¬¡çŸ©é˜µä¹˜æ³•)")
        
        if elapsed > 1.0:
            print(f"  âš ï¸  GPUæ€§èƒ½è¾ƒä½ï¼Œå¯èƒ½æ˜¯:")
            print(f"     - ä½¿ç”¨çš„æ˜¯é›†æˆæ˜¾å¡")
            print(f"     - GPUé©±åŠ¨æœªæ­£ç¡®å®‰è£…")
            print(f"     - GPUè¢«å…¶ä»–ç¨‹åºå ç”¨")
    except Exception as e:
        print(f"  âš ï¸  GPUæµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True


def format_time(seconds):
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if seconds < 60:
        return f"{seconds:.0f}ç§’"
    elif seconds < 3600:
        return f"{seconds // 60:.0f}åˆ†{seconds % 60:.0f}ç§’"
    else:
        return f"{seconds // 3600:.0f}å°æ—¶{(seconds % 3600) // 60:.0f}åˆ†"


def train_epoch(model, train_loader, criterion, optimizer, device, epoch, total_epochs, scaler=None):
    """è®­ç»ƒä¸€ä¸ªepoch - æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ"""
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    start_time = time.time()
    
    for batch_idx, (inputs, labels) in enumerate(train_loader):
        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)
        
        optimizer.zero_grad()
        
        # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        if scaler is not None and device.type == 'cuda':
            with torch.amp.autocast('cuda'):
                outputs = model(inputs)
                loss = criterion(outputs, labels)
            
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            # CPUè®­ç»ƒæˆ–ä¸ä½¿ç”¨æ··åˆç²¾åº¦
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
        
        # ç»Ÿè®¡
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
        
        # æ˜¾ç¤ºè¿›åº¦ - å‡å°‘æ‰“å°é¢‘ç‡æå‡é€Ÿåº¦
        if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(train_loader):
            avg_loss = running_loss / (batch_idx + 1)
            accuracy = 100. * correct / total
            progress = (batch_idx + 1) / len(train_loader) * 100
            
            # ä¼°ç®—å‰©ä½™æ—¶é—´
            elapsed = time.time() - start_time
            if batch_idx > 0:
                time_per_batch = elapsed / (batch_idx + 1)
                remaining_batches = len(train_loader) - (batch_idx + 1)
                eta = time_per_batch * remaining_batches
                eta_str = format_time(eta)
            else:
                eta_str = "è®¡ç®—ä¸­..."
            
            bar_length = 30
            filled = int(bar_length * (batch_idx + 1) / len(train_loader))
            bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
            
            print(f"\r  Epoch [{epoch}/{total_epochs}] "
                  f"[{bar}] {progress:.1f}% "
                  f"Loss: {avg_loss:.4f} Acc: {accuracy:.2f}% "
                  f"ETA: {eta_str}", end='', flush=True)
    
    print()  # æ¢è¡Œ
    
    epoch_loss = running_loss / len(train_loader)
    epoch_acc = 100. * correct / total
    epoch_time = time.time() - start_time
    
    return epoch_loss, epoch_acc, epoch_time


def validate(model, val_loader, criterion, device):
    """éªŒè¯æ¨¡å‹"""
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
    
    val_loss = running_loss / len(val_loader)
    val_acc = 100. * correct / total
    
    return val_loss, val_acc


def clean_augmented_images(training_data_dir):
    """æ¸…ç†å¢å¼ºçš„å›¾ç‰‡"""
    print("\nğŸ§¹ æ¸…ç†å¢å¼ºå›¾ç‰‡...")
    
    deleted_count = 0
    for class_dir in training_data_dir.iterdir():
        if not class_dir.is_dir():
            continue
        
        # åˆ é™¤å¢å¼ºå›¾ç‰‡
        for img_path in class_dir.glob("*_aug_*.png"):
            img_path.unlink()
            deleted_count += 1
    
    print(f"  âœ“ å·²åˆ é™¤ {deleted_count} å¼ å¢å¼ºå›¾ç‰‡")


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    print("\n" + "=" * 80)
    print("ğŸ¯ é¡µé¢åˆ†ç±»å™¨è®­ç»ƒ (PyTorch)")
    print("=" * 80)
    
    # é…ç½®
    script_dir = Path(__file__).parent.parent
    training_data_dir = script_dir / "training_data"
    models_dir = script_dir / "models"
    models_dir.mkdir(exist_ok=True)
    
    # è®­ç»ƒå‚æ•°
    BATCH_SIZE = 256  # ä¿æŒ256ä»¥ç¡®ä¿è®­ç»ƒè´¨é‡
    EPOCHS = 30
    LEARNING_RATE = 0.001
    IMG_SIZE = (224, 224)  # ä¿æŒ224ä»¥ç¡®ä¿å‡†ç¡®ç‡
    VAL_INTERVAL = 5  # æ¯5è½®éªŒè¯ä¸€æ¬¡
    
    print(f"\nğŸ“ æ•°æ®ç›®å½•: {training_data_dir}")
    print(f"ğŸ’¾ æ¨¡å‹ç›®å½•: {models_dir}")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥GPUçŠ¶æ€
    gpu_available = check_gpu_status()
    
    # æ£€æŸ¥è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ–¥ï¸  è®¾å¤‡: {device}")
    if device.type == 'cuda':
        print(f"  â€¢ GPU: {torch.cuda.get_device_name(0)}")
        print(f"  â€¢ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        print(f"  â€¢ CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"  â€¢ cuDNNå¯ç”¨: {torch.backends.cudnn.enabled}")
        # å¯ç”¨cuDNNè‡ªåŠ¨ä¼˜åŒ–
        torch.backends.cudnn.benchmark = True
    else:
        print(f"  âš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦ä¼šå¾ˆæ…¢ï¼‰")
    
    # è®­ç»ƒå‚æ•°
    print(f"\nâš™ï¸  è®­ç»ƒå‚æ•°:")
    print(f"  â€¢ Batch Size: {BATCH_SIZE}")
    print(f"  â€¢ Epochs: {EPOCHS}")
    print(f"  â€¢ Learning Rate: {LEARNING_RATE}")
    print(f"  â€¢ Image Size: {IMG_SIZE[0]}x{IMG_SIZE[1]}")
    print(f"  â€¢ éªŒè¯é—´éš”: æ¯{VAL_INTERVAL}è½®éªŒè¯ä¸€æ¬¡")
    print(f"  â€¢ æ•°æ®åŠ è½½: 4çº¿ç¨‹ (è®­ç»ƒ) / 2çº¿ç¨‹ (éªŒè¯) + persistent_workers")
    
    # æ•°æ®å˜æ¢
    transform = transforms.Compose([
        transforms.Resize(IMG_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # åŠ è½½æ•°æ®é›†
    print(f"\nğŸ“¦ åŠ è½½æ•°æ®é›†...")
    dataset = PageClassifierDataset(training_data_dir, transform=transform)
    
    if len(dataset) == 0:
        print("\nâŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæ•°æ®")
        return
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    print(f"\nğŸ“Š æ•°æ®é›†åˆ’åˆ†:")
    print(f"  â€¢ è®­ç»ƒé›†: {len(train_dataset)} å¼ ")
    print(f"  â€¢ éªŒè¯é›†: {len(val_dataset)} å¼ ")
    print(f"  â€¢ ç±»åˆ«æ•°: {len(dataset.classes)}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä½¿ç”¨å¤šçº¿ç¨‹åŠ é€Ÿ
    # Windowsä¸Šä½¿ç”¨4çº¿ç¨‹ï¼Œé…åˆpersistent_workersé¿å…é‡å¤åˆ›å»ºè¿›ç¨‹
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, 
                             num_workers=4, pin_memory=True if device.type == 'cuda' else False,
                             persistent_workers=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, 
                           num_workers=2, pin_memory=True if device.type == 'cuda' else False,
                           persistent_workers=True)
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸  åˆ›å»ºæ¨¡å‹...")
    model = PageClassifier(num_classes=len(dataset.classes))
    model = model.to(device)
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)
    
    # åˆ›å»ºæ··åˆç²¾åº¦è®­ç»ƒçš„GradScalerï¼ˆä»…GPUï¼‰
    scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None
    if scaler:
        print(f"  â€¢ æ··åˆç²¾åº¦è®­ç»ƒ(AMP): å·²å¯ç”¨ âš¡")
    
    # è®­ç»ƒ
    print("\n" + "=" * 80)
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    print("=" * 80)
    
    best_val_acc = 0.0
    best_model_path = models_dir / "page_classifier_pytorch_best.pth"
    training_start_time = time.time()
    
    history = {
        'train_loss': [],
        'train_acc': [],
        'val_loss': [],
        'val_acc': []
    }
    
    for epoch in range(1, EPOCHS + 1):
        epoch_start_time = time.time()
        
        # è®­ç»ƒ
        train_loss, train_acc, train_time = train_epoch(
            model, train_loader, criterion, optimizer, device, epoch, EPOCHS, scaler
        )
        
        # è®°å½•è®­ç»ƒå†å²
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        
        # åªåœ¨æŒ‡å®šé—´éš”æˆ–æœ€åä¸€è½®è¿›è¡ŒéªŒè¯
        should_validate = (epoch % VAL_INTERVAL == 0) or (epoch == EPOCHS)
        
        if should_validate:
            # éªŒè¯
            val_loss, val_acc = validate(model, val_loader, criterion, device)
            
            # å­¦ä¹ ç‡è°ƒæ•´
            scheduler.step(val_loss)
            
            # è®°å½•éªŒè¯å†å²
            history['val_loss'].append(val_loss)
            history['val_acc'].append(val_acc)
        else:
            # ä¸éªŒè¯æ—¶ä½¿ç”¨ä¸Šä¸€æ¬¡çš„éªŒè¯ç»“æœ
            val_loss = history['val_loss'][-1] if history['val_loss'] else 0.0
            val_acc = history['val_acc'][-1] if history['val_acc'] else 0.0
        
        # è®¡ç®—æ—¶é—´
        epoch_time = time.time() - epoch_start_time
        elapsed_total = time.time() - training_start_time
        avg_epoch_time = elapsed_total / epoch
        remaining_epochs = EPOCHS - epoch
        eta_total = avg_epoch_time * remaining_epochs
        
        # æ˜¾ç¤ºç»“æœ
        print(f"  ğŸ“ˆ è®­ç»ƒ - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%")
        if should_validate:
            print(f"  ğŸ“‰ éªŒè¯ - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%")
        else:
            print(f"  ğŸ“‰ éªŒè¯ - è·³è¿‡ (ä¸Šæ¬¡: Acc {val_acc:.2f}%)")
        print(f"  â±ï¸  è€—æ—¶: {format_time(epoch_time)} | "
              f"æ€»è€—æ—¶: {format_time(elapsed_total)} | "
              f"é¢„è®¡å‰©ä½™: {format_time(eta_total)}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåªåœ¨éªŒè¯æ—¶æ›´æ–°ï¼‰
        if should_validate and val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc,
                'val_loss': val_loss,
            }, best_model_path)
            print(f"  âœ¨ æ–°çš„æœ€ä½³æ¨¡å‹! éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%")
        
        print()
    
    # è®­ç»ƒå®Œæˆ
    total_time = time.time() - training_start_time
    
    print("=" * 80)
    print("âœ… è®­ç»ƒå®Œæˆ!")
    print("=" * 80)
    
    print(f"\nğŸ“Š è®­ç»ƒç»Ÿè®¡:")
    print(f"  â€¢ æ€»è€—æ—¶: {format_time(total_time)}")
    print(f"  â€¢ å¹³å‡æ¯è½®: {format_time(total_time / EPOCHS)}")
    print(f"  â€¢ æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
    print(f"  â€¢ æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {history['train_acc'][-1]:.2f}%")
    print(f"  â€¢ æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {history['val_acc'][-1]:.2f}%")
    
    # ä¿å­˜ç±»åˆ«åˆ—è¡¨
    classes_path = models_dir / "page_classes.json"
    with open(classes_path, 'w', encoding='utf-8') as f:
        json.dump(dataset.classes, f, ensure_ascii=False, indent=2)
    
    # ç”Ÿæˆæ¨¡å‹ç‰ˆæœ¬æ–‡ä»¶
    version_path = models_dir / "model_version.json"
    model_size_mb = best_model_path.stat().st_size / (1024 * 1024)
    classes_size_mb = classes_path.stat().st_size / (1024 * 1024)
    
    version_info = {
        "version": "1.0.0",
        "update_date": datetime.now().strftime("%Y-%m-%d"),
        "description": f"é¡µé¢åˆ†ç±»å™¨è®­ç»ƒå®Œæˆ - {len(dataset.classes)}ä¸ªç±»åˆ«",
        "models": {
            "page_classifier": {
                "version": "1.0.0",
                "file": "page_classifier_pytorch_best.pth",
                "size_mb": round(model_size_mb, 2),
                "description": "é¡µé¢åˆ†ç±»å™¨ï¼ˆPyTorchï¼‰"
            },
            "page_classes": {
                "version": "1.0.0",
                "file": "page_classes.json",
                "size_mb": round(classes_size_mb, 2),
                "description": "é¡µé¢ç±»åˆ«æ˜ å°„"
            }
        }
    }
    
    with open(version_path, 'w', encoding='utf-8') as f:
        json.dump(version_info, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ å·²ä¿å­˜:")
    print(f"  â€¢ æ¨¡å‹: {best_model_path}")
    print(f"  â€¢ ç±»åˆ«: {classes_path}")
    print(f"  â€¢ ç‰ˆæœ¬: {version_path}")
    
    # ä¸è‡ªåŠ¨æ¸…ç†å¢å¼ºå›¾ç‰‡ï¼Œç•™å¾…éªŒè¯åæ‰‹åŠ¨æ¸…ç†
    print(f"\nğŸ’¡ æç¤º: å¢å¼ºå›¾ç‰‡å·²ä¿ç•™ï¼Œå¯ç”¨äºéªŒè¯æ¨¡å‹")
    print(f"ğŸ’¡ æç¤º: éªŒè¯å®Œæˆåå¯æ‰‹åŠ¨åˆ é™¤å¢å¼ºå›¾ç‰‡")
    
    print(f"\nâ° å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    print("\nğŸ’¡ æç¤º: æ¨¡å‹å·²ä¿å­˜åˆ° models/ ç›®å½•")
    print("ğŸ’¡ æç¤º: å¯ä»¥ä½¿ç”¨è¯¥æ¨¡å‹è¿›è¡Œé¡µé¢åˆ†ç±»è¯†åˆ«")


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·å–æ¶ˆè®­ç»ƒ")
    except Exception as e:
        print(f"\n\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
