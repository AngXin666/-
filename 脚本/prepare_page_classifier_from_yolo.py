"""
ä»YOLOåŸå§‹æ ‡æ³¨å›¾å‡†å¤‡é¡µé¢åˆ†ç±»å™¨è®­ç»ƒæ•°æ®

ç”¨æ³•ï¼š
    python prepare_page_classifier_from_yolo.py
"""
import shutil
from pathlib import Path


def prepare_page_classifier_data():
    """ä»YOLOåŸå§‹æ ‡æ³¨å›¾å‡†å¤‡é¡µé¢åˆ†ç±»å™¨è®­ç»ƒæ•°æ®ï¼ˆåªå‡†å¤‡æŒ‡å®šçš„4ä¸ªç±»åˆ«ï¼‰"""
    print("=" * 60)
    print("å‡†å¤‡é¡µé¢åˆ†ç±»å™¨è®­ç»ƒæ•°æ®ï¼ˆä»…4ä¸ªç±»åˆ«ï¼‰")
    print("=" * 60)
    
    # å®šä¹‰æºç›®å½•å’Œç›®æ ‡ç›®å½•çš„æ˜ å°„
    # æ ¼å¼ï¼š(æºç›®å½•, ç›®æ ‡é¡µé¢ç±»å‹åç§°)
    mappings = [
        ("åŸå§‹æ ‡æ³¨å›¾/é¦–é¡µ_20260130_030231/images", "é¦–é¡µ"),
        ("åŸå§‹æ ‡æ³¨å›¾/ç­¾åˆ°é¡µ_20260130_014729/images", "ç­¾åˆ°é¡µ"),
        ("åŸå§‹æ ‡æ³¨å›¾/æ¸©é¦¨æç¤º_20260130_015651/images", "æ¸©é¦¨æç¤º"),
        ("åŸå§‹æ ‡æ³¨å›¾/ç­¾åˆ°æˆåŠŸå¼¹çª—_20260130_013633/images", "ç­¾åˆ°å¼¹çª—"),  # ç­¾åˆ°æˆåŠŸå¼¹çª— -> ç­¾åˆ°å¼¹çª—
    ]
    
    # åˆ›å»ºæ–°çš„ç›®æ ‡æ ¹ç›®å½•ï¼ˆåªåŒ…å«è¿™4ä¸ªç±»åˆ«ï¼‰
    target_root = Path("page_classifier_dataset_4classes")
    
    # å¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
    if target_root.exists():
        print(f"\nğŸ—‘ï¸  åˆ é™¤æ—§çš„æ•°æ®é›†ç›®å½•...")
        shutil.rmtree(target_root)
    
    print(f"\nğŸ“‚ ç›®æ ‡ç›®å½•: {target_root}")
    print(f"\nğŸ” æ£€æŸ¥æºç›®å½•...")
    
    # æ£€æŸ¥æ‰€æœ‰æºç›®å½•æ˜¯å¦å­˜åœ¨
    valid_mappings = []
    for source_dir, page_type in mappings:
        source_path = Path(source_dir)
        if source_path.exists():
            image_count = len(list(source_path.glob("*.png")) + list(source_path.glob("*.jpg")))
            print(f"  âœ“ {page_type}: {source_dir} ({image_count}å¼ å›¾ç‰‡)")
            valid_mappings.append((source_path, page_type, image_count))
        else:
            print(f"  âœ— {page_type}: {source_dir} (ä¸å­˜åœ¨)")
    
    if not valid_mappings:
        print(f"\nâŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æºç›®å½•")
        return
    
    print(f"\nğŸ“Š æ‰¾åˆ° {len(valid_mappings)} ä¸ªæœ‰æ•ˆçš„é¡µé¢ç±»å‹")
    
    # è¯¢é—®æ˜¯å¦ç»§ç»­
    total_images = sum(count for _, _, count in valid_mappings)
    print(f"\nå°†å¤åˆ¶ {total_images} å¼ å›¾ç‰‡åˆ°æ–°çš„é¡µé¢åˆ†ç±»å™¨æ•°æ®é›†")
    print(f"ç›®æ ‡ç›®å½•: {target_root}")
    print(f"âš ï¸  æ³¨æ„ï¼šåªåŒ…å«è¿™4ä¸ªç±»åˆ«ï¼Œä¸å½±å“åŸæœ‰çš„ page_classifier_dataset")
    
    # å¤åˆ¶å›¾ç‰‡
    print(f"\nğŸ“¦ å¼€å§‹å¤åˆ¶å›¾ç‰‡...")
    copied_count = 0
    
    for source_path, page_type, image_count in valid_mappings:
        # åˆ›å»ºç›®æ ‡ç›®å½•
        target_dir = target_root / page_type
        target_dir.mkdir(parents=True, exist_ok=True)
        
        # å¤åˆ¶æ‰€æœ‰å›¾ç‰‡
        images = list(source_path.glob("*.png")) + list(source_path.glob("*.jpg"))
        
        for img_path in images:
            target_path = target_dir / img_path.name
            shutil.copy2(img_path, target_path)
            copied_count += 1
        
        print(f"  âœ“ {page_type}: å·²å¤åˆ¶ {len(images)} å¼ å›¾ç‰‡")
    
    print(f"\nâœ… å¤åˆ¶å®Œæˆ!")
    print(f"  æ€»è®¡: {copied_count} å¼ å›¾ç‰‡")
    print(f"  ä½ç½®: {target_root}")
    
    # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„å›¾ç‰‡æ•°é‡
    print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡ï¼ˆä»…4ä¸ªç±»åˆ«ï¼‰:")
    for page_type_dir in sorted(target_root.iterdir()):
        if page_type_dir.is_dir():
            count = len(list(page_type_dir.glob("*.png")) + list(page_type_dir.glob("*.jpg")))
            print(f"  {page_type_dir.name}: {count}å¼ ")
    
    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print(f"  1. æ£€æŸ¥æ•°æ®é›†: æ‰“å¼€ {target_root} æŸ¥çœ‹å›¾ç‰‡")
    print(f"  2. è®­ç»ƒæ¨¡å‹: python train_page_classifier_pytorch.py --dataset {target_root}")


if __name__ == "__main__":
    prepare_page_classifier_data()
