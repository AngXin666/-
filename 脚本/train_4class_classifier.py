"""
è®­ç»ƒ4ç±»é¡µé¢åˆ†ç±»å™¨ï¼ˆé¦–é¡µã€ç­¾åˆ°é¡µã€æ¸©é¦¨æç¤ºã€ç­¾åˆ°å¼¹çª—ï¼‰

ç”¨æ³•ï¼š
    python train_4class_classifier.py
"""
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from pathlib import Path
from PIL import Image
import random


class PageDataset(Dataset):
    """é¡µé¢æ•°æ®é›†"""
    def __init__(self, root_dir, transform=None):
        self.root_dir = Path(root_dir)
        self.transform = transform
        self.samples = []
        self.classes = []
        
        # æ‰«ææ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
        for class_dir in sorted(self.root_dir.iterdir()):
            if class_dir.is_dir():
                class_name = class_dir.name
                self.classes.append(class_name)
                class_idx = len(self.classes) - 1
                
                # æ‰«æè¯¥ç±»åˆ«ä¸‹çš„æ‰€æœ‰å›¾ç‰‡
                for img_path in class_dir.glob("*.png"):
                    self.samples.append((str(img_path), class_idx))
                for img_path in class_dir.glob("*.jpg"):
                    self.samples.append((str(img_path), class_idx))
        
        print(f"  æ‰¾åˆ° {len(self.classes)} ä¸ªç±»åˆ«: {self.classes}")
        print(f"  æ€»å›¾ç‰‡æ•°: {len(self.samples)}")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        image = Image.open(img_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        return image, label


def train_model():
    """è®­ç»ƒ4ç±»é¡µé¢åˆ†ç±»å™¨"""
    print("=" * 60)
    print("è®­ç»ƒ4ç±»é¡µé¢åˆ†ç±»å™¨")
    print("=" * 60)
    
    # é…ç½®
    dataset_dir = "page_classifier_dataset_4classes_augmented"  # ä½¿ç”¨å¢å¼ºåçš„æ•°æ®é›†
    batch_size = 32
    num_epochs = 30
    learning_rate = 0.001
    
    # æ£€æŸ¥GPU
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ–¥ï¸  è®¾å¤‡: {device}")
    if device.type == 'cuda':
        print(f"  GPU: {torch.cuda.get_device_name(0)}")
    
    # æ•°æ®å¢å¼ºå’Œé¢„å¤„ç†
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # åŠ è½½æ•°æ®é›†
    print(f"\nğŸ“¦ åŠ è½½æ•°æ®é›†...")
    full_dataset = PageDataset(dataset_dir, transform=train_transform)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›† (80/20)
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    
    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
    torch.manual_seed(42)
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size]
    )
    
    # ä¸ºéªŒè¯é›†è®¾ç½®ä¸åŒçš„transform
    val_dataset.dataset.transform = val_transform
    
    print(f"  è®­ç»ƒé›†: {train_size} å¼ ")
    print(f"  éªŒè¯é›†: {val_size} å¼ ")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True,
        num_workers=0  # Windowsä½¿ç”¨0
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0
    )
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸  åˆ›å»ºæ¨¡å‹...")
    num_classes = len(full_dataset.classes)
    model = models.resnet18(pretrained=True)
    model.fc = nn.Linear(model.fc.in_features, num_classes)
    model = model.to(device)
    
    print(f"  æ¨¡å‹: ResNet18")
    print(f"  ç±»åˆ«æ•°: {num_classes}")
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
    
    # è®­ç»ƒ
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    print(f"  è½®æ•°: {num_epochs}")
    print(f"  æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"  å­¦ä¹ ç‡: {learning_rate}")
    
    best_acc = 0.0
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            train_total += labels.size(0)
            train_correct += predicted.eq(labels).sum().item()
        
        train_acc = 100. * train_correct / train_total
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                val_total += labels.size(0)
                val_correct += predicted.eq(labels).sum().item()
        
        val_acc = 100. * val_correct / val_total
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # æ‰“å°è¿›åº¦
        print(f"  Epoch [{epoch+1}/{num_epochs}] "
              f"Train Loss: {train_loss/len(train_loader):.4f} "
              f"Train Acc: {train_acc:.2f}% "
              f"Val Loss: {val_loss/len(val_loader):.4f} "
              f"Val Acc: {val_acc:.2f}%")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc,
                'classes': full_dataset.classes,
            }, 'page_classifier_4classes_best.pth')
            print(f"    âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%)")
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
    print(f"  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.2f}%")
    print(f"  æ¨¡å‹å·²ä¿å­˜: page_classifier_4classes_best.pth")
    
    # ä¿å­˜ç±»åˆ«æ˜ å°„
    import json
    with open('page_classes_4.json', 'w', encoding='utf-8') as f:
        json.dump({
            'classes': full_dataset.classes,
            'num_classes': len(full_dataset.classes)
        }, f, ensure_ascii=False, indent=2)
    
    print(f"  ç±»åˆ«æ˜ å°„å·²ä¿å­˜: page_classes_4.json")


if __name__ == "__main__":
    train_model()
