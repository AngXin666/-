"""æ ¹æ®é¡µé¢ç±»å‹æ™ºèƒ½æ ‡æ³¨å­¦ä¹ å™¨æ¨èçš„ä½ç½®"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from button_position_learner import ButtonPositionLearner
from ocr_region_learner import OCRRegionLearner
from pathlib import Path
import json
import cv2
import numpy as np

# åˆ›å»ºè¾“å‡ºç›®å½•
output_dir = Path("learning_visualization")
output_dir.mkdir(exist_ok=True)

# å®šä¹‰é¡µé¢ç±»å‹å’Œå¯¹åº”çš„æ ‡æ³¨å…ƒç´ 
PAGE_ANNOTATIONS = {
    'home': {
        'buttons': ['home_checkin_button'],
        'regions': []
    },
    'checkin': {
        'buttons': [],
        'regions': ['checkin_total_times', 'checkin_remaining_times']
    },
    'profile': {
        'buttons': [],
        'regions': ['profile_balance', 'profile_points', 'profile_vouchers', 'profile_coupons']
    },
    'wallet': {
        'buttons': ['wallet_balance_button'],
        'regions': []
    }
}

def detect_page_type(img_path):
    """æ ¹æ®æ–‡ä»¶è·¯å¾„æˆ–å†…å®¹æ£€æµ‹é¡µé¢ç±»å‹"""
    path_str = str(img_path).lower()
    
    # æ ¹æ®è·¯å¾„åˆ¤æ–­
    if 'checkin' in path_str or 'ç­¾åˆ°' in path_str:
        return 'checkin'
    elif 'profile' in path_str or 'ä¸ªäºº' in path_str:
        return 'profile'
    elif 'wallet' in path_str or 'é’±åŒ…' in path_str:
        return 'wallet'
    elif 'home' in path_str or 'é¦–é¡µ' in path_str:
        return 'home'
    
    # é»˜è®¤è¿”å›Noneï¼Œè¡¨ç¤ºæ ‡æ³¨æ‰€æœ‰å…ƒç´ 
    return None

def draw_button_position(img, button_name, position, stats):
    """åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶æŒ‰é’®ä½ç½®"""
    x, y = position
    
    # ç»˜åˆ¶æ¨èä½ç½®ï¼ˆçº¢è‰²åœ†ç‚¹ï¼‰
    cv2.circle(img, (x, y), 10, (0, 0, 255), -1)
    cv2.circle(img, (x, y), 15, (0, 0, 255), 3)
    
    # ç»˜åˆ¶æ ‡å‡†å·®èŒƒå›´ï¼ˆåŠé€æ˜çŸ©å½¢ï¼‰
    if stats and stats['x_stdev'] > 0:
        x_std = max(int(stats['x_stdev'] * 3), 20)  # 3å€æ ‡å‡†å·®ï¼Œæœ€å°20åƒç´ 
        y_std = max(int(stats['y_stdev'] * 3), 20)
        
        overlay = img.copy()
        cv2.rectangle(overlay, 
                     (x - x_std, y - y_std), 
                     (x + x_std, y + y_std), 
                     (0, 255, 0), -1)
        cv2.addWeighted(overlay, 0.15, img, 0.85, 0, img)
        
        # ç»˜åˆ¶è¾¹æ¡†
        cv2.rectangle(img, 
                     (x - x_std, y - y_std), 
                     (x + x_std, y + y_std), 
                     (0, 255, 0), 2)
    
    # æ·»åŠ æ–‡å­—æ ‡ç­¾
    label = button_name.replace('_', ' ')
    label_pos = f"({x}, {y})"
    
    # æ–‡å­—èƒŒæ™¯
    font = cv2.FONT_HERSHEY_SIMPLEX
    (w1, h1), _ = cv2.getTextSize(label, font, 0.7, 2)
    (w2, h2), _ = cv2.getTextSize(label_pos, font, 0.5, 1)
    
    bg_x = x + 20
    bg_y = y - 45
    bg_w = max(w1, w2) + 20
    bg_h = 50
    
    cv2.rectangle(img, (bg_x, bg_y), (bg_x + bg_w, bg_y + bg_h), (0, 0, 0), -1)
    cv2.rectangle(img, (bg_x, bg_y), (bg_x + bg_w, bg_y + bg_h), (0, 0, 255), 2)
    
    # ç»˜åˆ¶æ–‡å­—
    cv2.putText(img, label, (bg_x + 10, bg_y + 25), font, 0.7, (255, 255, 255), 2)
    cv2.putText(img, label_pos, (bg_x + 10, bg_y + 43), font, 0.5, (200, 200, 200), 1)

def draw_ocr_region(img, region_name, region, stats):
    """åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶OCRåŒºåŸŸ"""
    x, y, w, h = region
    
    # ç»˜åˆ¶æ¨èåŒºåŸŸï¼ˆè“è‰²çŸ©å½¢ï¼‰
    overlay = img.copy()
    cv2.rectangle(overlay, (x, y), (x + w, y + h), (255, 100, 0), -1)
    cv2.addWeighted(overlay, 0.25, img, 0.75, 0, img)
    
    # ç»˜åˆ¶è¾¹æ¡†
    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 100, 0), 3)
    
    # æ·»åŠ æ–‡å­—æ ‡ç­¾
    label = region_name.replace('_', ' ')
    label_size = f"{w}x{h}"
    
    # æ–‡å­—èƒŒæ™¯
    font = cv2.FONT_HERSHEY_SIMPLEX
    (w1, h1), _ = cv2.getTextSize(label, font, 0.6, 2)
    (w2, h2), _ = cv2.getTextSize(label_size, font, 0.5, 1)
    
    bg_w = max(w1, w2) + 20
    bg_h = 45
    bg_x = x
    bg_y = y - bg_h - 5
    
    # å¦‚æœæ ‡ç­¾ä¼šè¶…å‡ºå›¾ç‰‡é¡¶éƒ¨ï¼Œæ”¾åˆ°åŒºåŸŸä¸‹æ–¹
    if bg_y < 0:
        bg_y = y + h + 5
    
    cv2.rectangle(img, (bg_x, bg_y), (bg_x + bg_w, bg_y + bg_h), (0, 0, 0), -1)
    cv2.rectangle(img, (bg_x, bg_y), (bg_x + bg_w, bg_y + bg_h), (255, 100, 0), 2)
    
    # ç»˜åˆ¶æ–‡å­—
    cv2.putText(img, label, (bg_x + 10, bg_y + 22), font, 0.6, (255, 255, 255), 2)
    cv2.putText(img, label_size, (bg_x + 10, bg_y + 38), font, 0.5, (200, 200, 200), 1)

def annotate_screenshot(img_path, button_learner, ocr_learner, page_type=None):
    """åœ¨æˆªå›¾ä¸Šæ ‡æ³¨å­¦ä¹ åˆ°çš„ä½ç½®"""
    # è¯»å–å›¾ç‰‡
    img = cv2.imread(str(img_path))
    if img is None:
        return None
    
    # è·å–å›¾ç‰‡å°ºå¯¸
    img_height, img_width = img.shape[:2]
    print(f"  å›¾ç‰‡å°ºå¯¸: {img_width}x{img_height}")
    
    # æ£€æµ‹é¡µé¢ç±»å‹
    if page_type is None:
        page_type = detect_page_type(img_path)
    
    if page_type:
        print(f"  é¡µé¢ç±»å‹: {page_type}")
        annotations = PAGE_ANNOTATIONS.get(page_type, {'buttons': [], 'regions': []})
    else:
        print(f"  é¡µé¢ç±»å‹: æœªçŸ¥ï¼ˆæ ‡æ³¨æ‰€æœ‰å…ƒç´ ï¼‰")
        annotations = None
    
    annotated = False
    
    # æ ‡æ³¨æŒ‰é’®ä½ç½®
    global_file = Path("runtime_data/button_positions/global.json")
    if global_file.exists():
        with open(global_file, 'r', encoding='utf-8') as f:
            button_data = json.load(f)
        
        for button_name in button_data.keys():
            # å¦‚æœæŒ‡å®šäº†é¡µé¢ç±»å‹ï¼Œåªæ ‡æ³¨ç›¸å…³æŒ‰é’®
            if annotations and button_name not in annotations['buttons']:
                continue
            
            best_pos = button_learner.get_best_position(button_name, min_samples=5)
            if best_pos:
                # æ£€æŸ¥åæ ‡æ˜¯å¦åœ¨å›¾ç‰‡èŒƒå›´å†…
                if 0 <= best_pos[0] < img_width and 0 <= best_pos[1] < img_height:
                    stats = button_learner.get_statistics(button_name)
                    draw_button_position(img, button_name, best_pos, stats)
                    print(f"    âœ“ æ ‡æ³¨æŒ‰é’®: {button_name} at ({best_pos[0]}, {best_pos[1]})")
                    annotated = True
    
    # æ ‡æ³¨OCRåŒºåŸŸ
    global_file = Path("runtime_data/ocr_regions/global.json")
    if global_file.exists():
        with open(global_file, 'r', encoding='utf-8') as f:
            ocr_data = json.load(f)
        
        for region_name in ocr_data.keys():
            # å¦‚æœæŒ‡å®šäº†é¡µé¢ç±»å‹ï¼Œåªæ ‡æ³¨ç›¸å…³åŒºåŸŸ
            if annotations and region_name not in annotations['regions']:
                continue
            
            best_region = ocr_learner.get_best_region(region_name, min_samples=5)
            if best_region:
                x, y, w, h = best_region
                # æ£€æŸ¥åŒºåŸŸæ˜¯å¦åœ¨å›¾ç‰‡èŒƒå›´å†…
                if 0 <= x < img_width and 0 <= y < img_height and x + w <= img_width and y + h <= img_height:
                    stats = ocr_learner.get_statistics(region_name)
                    draw_ocr_region(img, region_name, best_region, stats)
                    print(f"    âœ“ æ ‡æ³¨åŒºåŸŸ: {region_name} at ({x}, {y}, {w}, {h})")
                    annotated = True
    
    return img if annotated else None

def find_screenshots_by_folder():
    """æŒ‰æ–‡ä»¶å¤¹åˆ†ç±»æŸ¥æ‰¾æˆªå›¾"""
    screenshot_folders = {
        'checkin': [
            Path("checkin_screenshots"),
            Path("screenshots/checkin")
        ],
        'exception': [
            Path("screenshots/exception")
        ]
    }
    
    results = {}
    for folder_type, paths in screenshot_folders.items():
        screenshots = []
        for dir_path in paths:
            if dir_path.exists():
                # æŸ¥æ‰¾æœ€æ–°çš„æˆªå›¾
                for img_file in sorted(dir_path.glob("**/*.png"), 
                                      key=lambda x: x.stat().st_mtime, reverse=True)[:5]:
                    screenshots.append(img_file)
        
        if screenshots:
            results[folder_type] = screenshots
    
    return results

def main():
    print("\næ ¹æ®é¡µé¢ç±»å‹æ™ºèƒ½æ ‡æ³¨å­¦ä¹ å™¨æ¨èçš„ä½ç½®")
    print("=" * 60)
    
    # åˆå§‹åŒ–å­¦ä¹ å™¨
    button_learner = ButtonPositionLearner()
    ocr_learner = OCRRegionLearner()
    
    # æŒ‰æ–‡ä»¶å¤¹æŸ¥æ‰¾æˆªå›¾
    print("\næ­£åœ¨æŸ¥æ‰¾æˆªå›¾...")
    screenshots_by_folder = find_screenshots_by_folder()
    
    if not screenshots_by_folder:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æˆªå›¾æ–‡ä»¶")
        return
    
    total_annotated = 0
    
    for folder_type, screenshots in screenshots_by_folder.items():
        print(f"\n{'='*60}")
        print(f"å¤„ç† {folder_type} æ–‡ä»¶å¤¹ ({len(screenshots)} å¼ å›¾ç‰‡)")
        print(f"{'='*60}")
        
        # æ ¹æ®æ–‡ä»¶å¤¹ç±»å‹ç¡®å®šé¡µé¢ç±»å‹
        page_type = 'checkin' if folder_type == 'checkin' else None
        
        for i, img_path in enumerate(screenshots, 1):
            print(f"\n[{i}/{len(screenshots)}] å¤„ç†: {img_path.name}")
            
            annotated_img = annotate_screenshot(img_path, button_learner, ocr_learner, page_type)
            
            if annotated_img is not None:
                # ä¿å­˜æ ‡æ³¨åçš„å›¾ç‰‡
                output_path = output_dir / f"{folder_type}_annotated_{img_path.name}"
                cv2.imwrite(str(output_path), annotated_img)
                print(f"  âœ… å·²ä¿å­˜: {output_path.name}")
                total_annotated += 1
            else:
                print(f"  âš ï¸ è·³è¿‡ï¼ˆæ— ç›¸å…³æ ‡æ³¨ï¼‰")
    
    print("\n" + "=" * 60)
    print(f"âœ… å®Œæˆï¼å…±æ ‡æ³¨ {total_annotated} å¼ å›¾ç‰‡")
    print(f"ğŸ“ æ ‡æ³¨å›¾ç‰‡ä¿å­˜åœ¨: {output_dir.absolute()}")
    
    # æ‰“å¼€æ–‡ä»¶å¤¹
    if total_annotated > 0:
        print("\næ­£åœ¨æ‰“å¼€æ–‡ä»¶å¤¹...")
        import subprocess
        subprocess.run(['explorer', str(output_dir.absolute())])
    
    print("\nå›¾ä¾‹è¯´æ˜ï¼š")
    print("  ğŸ”´ çº¢è‰²åœ†ç‚¹ = æŒ‰é’®æ¨èä½ç½®")
    print("  ğŸŸ¢ ç»¿è‰²çŸ©å½¢ = æŒ‰é’®ä½ç½®æ ‡å‡†å·®èŒƒå›´ï¼ˆ3å€æ ‡å‡†å·®ï¼‰")
    print("  ğŸ”µ è“è‰²çŸ©å½¢ = OCRåŒºåŸŸæ¨èä½ç½®")
    print("=" * 60)

if __name__ == "__main__":
    main()
