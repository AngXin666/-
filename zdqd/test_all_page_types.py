"""
æµ‹è¯•æ‰€æœ‰é¡µé¢ç±»å‹çš„è¯†åˆ«å‡†ç¡®ç‡
"""
import sys
from pathlib import Path
import os
import json
import random

sys.path.insert(0, str(Path(__file__).parent / 'src'))

try:
    from PIL import Image
    HAS_PIL = True
except ImportError:
    HAS_PIL = False
    print("âŒ PILæœªå®‰è£…")
    sys.exit(1)

try:
    import torch
    import torch.nn as nn
    from torchvision import transforms, models
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False
    print("âŒ PyTorchæœªå®‰è£…")
    sys.exit(1)


def test_all_page_types():
    """æµ‹è¯•æ‰€æœ‰é¡µé¢ç±»å‹"""
    print("=" * 70)
    print("æµ‹è¯•æ‰€æœ‰é¡µé¢ç±»å‹çš„è¯†åˆ«å‡†ç¡®ç‡")
    print("=" * 70)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    print("\n[1] åŠ è½½æ¨¡å‹å’Œç±»åˆ«...")
    model_path = 'page_classifier_pytorch_best.pth'
    classes_path = 'page_classes.json'
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    if not os.path.exists(classes_path):
        print(f"âŒ ç±»åˆ«æ–‡ä»¶ä¸å­˜åœ¨: {classes_path}")
        return
    
    # åŠ è½½ç±»åˆ«åˆ—è¡¨
    with open(classes_path, 'r', encoding='utf-8') as f:
        classes = json.load(f)
    
    print(f"âœ“ å…±æœ‰ {len(classes)} ä¸ªç±»åˆ«")
    
    # åŠ è½½æ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"âœ“ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # å®šä¹‰æ¨¡å‹æ¶æ„
    class PageClassifier(nn.Module):
        def __init__(self, num_classes):
            super(PageClassifier, self).__init__()
            self.mobilenet = models.mobilenet_v2(weights=None)
            in_features = self.mobilenet.classifier[1].in_features
            self.mobilenet.classifier = nn.Sequential(
                nn.Dropout(0.2),
                nn.Linear(in_features, 128),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(128, num_classes)
            )
        
        def forward(self, x):
            return self.mobilenet(x)
    
    # åˆ›å»ºæ¨¡å‹
    model = PageClassifier(len(classes))
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, map_location=device)
    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model = model.to(device)
    model.eval()
    print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # å›¾åƒé¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # æµ‹è¯•æ•°æ®é›†ç›®å½•
    dataset_dir = Path('page_classifier_dataset_updated')
    
    if not dataset_dir.exists():
        print(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_dir}")
        return
    
    print(f"\n[2] å¼€å§‹æµ‹è¯•æ‰€æœ‰ç±»å‹...")
    print("=" * 70)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_correct = 0
    total_tested = 0
    results = {}
    
    # å¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œæµ‹è¯•
    for class_name in classes:
        class_dir = dataset_dir / class_name
        
        if not class_dir.exists():
            print(f"\nâš ï¸  è·³è¿‡ {class_name}: ç›®å½•ä¸å­˜åœ¨")
            continue
        
        # è·å–æ‰€æœ‰å›¾ç‰‡ï¼ˆåªæµ‹è¯•åŸå›¾ï¼Œä¸æµ‹è¯•å¢å¼ºå›¾ï¼‰
        all_images = [f for f in os.listdir(class_dir) if f.endswith('.png') and '_aug_' not in f]
        
        if len(all_images) == 0:
            print(f"\nâš ï¸  è·³è¿‡ {class_name}: æ²¡æœ‰åŸå§‹å›¾ç‰‡")
            continue
        
        # éšæœºé€‰æ‹©æœ€å¤š10å¼ å›¾ç‰‡æµ‹è¯•
        test_images = random.sample(all_images, min(10, len(all_images)))
        
        correct = 0
        tested = len(test_images)
        
        print(f"\næµ‹è¯• {class_name} ({tested}/{len(all_images)} å¼ å›¾ç‰‡)")
        print("-" * 70)
        
        for img_name in test_images:
            img_path = class_dir / img_name
            
            try:
                # åŠ è½½å›¾ç‰‡
                img = Image.open(img_path).convert('RGB')
                img_tensor = transform(img).unsqueeze(0).to(device)
                
                # é¢„æµ‹
                with torch.no_grad():
                    outputs = model(img_tensor)
                    probabilities = torch.nn.functional.softmax(outputs, dim=1)
                    confidence, predicted = torch.max(probabilities, 1)
                    
                    predicted_class = classes[predicted.item()]
                    confidence_pct = confidence.item() * 100
                
                # æ£€æŸ¥æ˜¯å¦æ­£ç¡®
                if predicted_class == class_name:
                    correct += 1
                    print(f"  âœ“ {img_name[:40]:40s} -> {predicted_class:20s} ({confidence_pct:5.2f}%)")
                else:
                    print(f"  âœ— {img_name[:40]:40s} -> {predicted_class:20s} ({confidence_pct:5.2f}%) [åº”ä¸º: {class_name}]")
            
            except Exception as e:
                print(f"  âœ— {img_name[:40]:40s} -> é”™è¯¯: {e}")
                tested -= 1
        
        # è®¡ç®—å‡†ç¡®ç‡
        if tested > 0:
            accuracy = (correct / tested) * 100
            results[class_name] = {
                'correct': correct,
                'tested': tested,
                'accuracy': accuracy
            }
            
            total_correct += correct
            total_tested += tested
            
            print(f"  å‡†ç¡®ç‡: {correct}/{tested} = {accuracy:.2f}%")
    
    # æ‰“å°æ€»ç»“
    print("\n" + "=" * 70)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 70)
    
    # æŒ‰å‡†ç¡®ç‡æ’åº
    sorted_results = sorted(results.items(), key=lambda x: x[1]['accuracy'])
    
    print("\nå‡†ç¡®ç‡ä»ä½åˆ°é«˜:")
    for class_name, stats in sorted_results:
        accuracy = stats['accuracy']
        correct = stats['correct']
        tested = stats['tested']
        
        if accuracy == 100:
            status = "âœ…"
        elif accuracy >= 90:
            status = "âš ï¸ "
        else:
            status = "âŒ"
        
        print(f"  {status} {class_name:25s}: {correct:2d}/{tested:2d} = {accuracy:6.2f}%")
    
    # æ€»ä½“å‡†ç¡®ç‡
    if total_tested > 0:
        overall_accuracy = (total_correct / total_tested) * 100
        print(f"\næ€»ä½“å‡†ç¡®ç‡: {total_correct}/{total_tested} = {overall_accuracy:.2f}%")
        
        if overall_accuracy == 100:
            print("\nğŸ‰ å®Œç¾ï¼æ‰€æœ‰ç±»å‹éƒ½èƒ½æ­£ç¡®è¯†åˆ«ï¼")
        elif overall_accuracy >= 95:
            print("\nâœ… ä¼˜ç§€ï¼å‡†ç¡®ç‡è¶…è¿‡95%")
        elif overall_accuracy >= 90:
            print("\nâš ï¸  è‰¯å¥½ï¼Œä½†æœ‰æ”¹è¿›ç©ºé—´")
        else:
            print("\nâŒ éœ€è¦æ”¹è¿›")


if __name__ == '__main__':
    test_all_page_types()
