"""åœ¨å®é™…æˆªå›¾ä¸Šæ ‡æ³¨å­¦ä¹ å™¨æ¨èçš„ä½ç½®"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from button_position_learner import ButtonPositionLearner
from ocr_region_learner import OCRRegionLearner
from pathlib import Path
import json
import cv2
import numpy as np
from datetime import datetime

# åˆ›å»ºè¾“å‡ºç›®å½•
output_dir = Path("learning_visualization")
output_dir.mkdir(exist_ok=True)

def find_latest_screenshots():
    """æŸ¥æ‰¾æœ€æ–°çš„æˆªå›¾"""
    screenshot_dirs = [
        Path("checkin_screenshots"),
        Path("screenshots/checkin"),
        Path("screenshots/exception")
    ]
    
    screenshots = []
    for dir_path in screenshot_dirs:
        if dir_path.exists():
            for img_file in dir_path.glob("**/*.png"):
                screenshots.append(img_file)
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
    screenshots.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    return screenshots[:10] if screenshots else []

def draw_button_position(img, button_name, position, stats):
    """åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶æŒ‰é’®ä½ç½®"""
    x, y = position
    
    # ç»˜åˆ¶æ¨èä½ç½®ï¼ˆçº¢è‰²åœ†ç‚¹ï¼‰
    cv2.circle(img, (x, y), 8, (0, 0, 255), -1)
    cv2.circle(img, (x, y), 12, (0, 0, 255), 2)
    
    # ç»˜åˆ¶æ ‡å‡†å·®èŒƒå›´ï¼ˆåŠé€æ˜çŸ©å½¢ï¼‰
    if stats:
        x_std = int(stats['x_stdev'] * 2)  # 2å€æ ‡å‡†å·®
        y_std = int(stats['y_stdev'] * 2)
        
        overlay = img.copy()
        cv2.rectangle(overlay, 
                     (x - x_std, y - y_std), 
                     (x + x_std, y + y_std), 
                     (0, 255, 0), -1)
        cv2.addWeighted(overlay, 0.2, img, 0.8, 0, img)
        
        # ç»˜åˆ¶è¾¹æ¡†
        cv2.rectangle(img, 
                     (x - x_std, y - y_std), 
                     (x + x_std, y + y_std), 
                     (0, 255, 0), 2)
    
    # æ·»åŠ æ–‡å­—æ ‡ç­¾
    label = f"{button_name}"
    label_pos = f"({x}, {y})"
    
    # æ–‡å­—èƒŒæ™¯
    (w1, h1), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
    (w2, h2), _ = cv2.getTextSize(label_pos, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
    
    cv2.rectangle(img, (x + 15, y - 35), (x + 15 + max(w1, w2) + 10, y + 5), (0, 0, 0), -1)
    
    # ç»˜åˆ¶æ–‡å­—
    cv2.putText(img, label, (x + 20, y - 15), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    cv2.putText(img, label_pos, (x + 20, y), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

def draw_ocr_region(img, region_name, region, stats):
    """åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶OCRåŒºåŸŸ"""
    x, y, w, h = region
    
    # ç»˜åˆ¶æ¨èåŒºåŸŸï¼ˆè“è‰²çŸ©å½¢ï¼‰
    overlay = img.copy()
    cv2.rectangle(overlay, (x, y), (x + w, y + h), (255, 0, 0), -1)
    cv2.addWeighted(overlay, 0.3, img, 0.7, 0, img)
    
    # ç»˜åˆ¶è¾¹æ¡†
    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)
    
    # æ·»åŠ æ–‡å­—æ ‡ç­¾
    label = f"{region_name}"
    label_size = f"{w}x{h}"
    
    # æ–‡å­—èƒŒæ™¯
    (w1, h1), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
    (w2, h2), _ = cv2.getTextSize(label_size, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)
    
    cv2.rectangle(img, (x, y - 30), (x + max(w1, w2) + 10, y), (0, 0, 0), -1)
    
    # ç»˜åˆ¶æ–‡å­—
    cv2.putText(img, label, (x + 5, y - 15), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    cv2.putText(img, label_size, (x + 5, y - 3), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

def annotate_screenshot(img_path, button_learner, ocr_learner):
    """åœ¨æˆªå›¾ä¸Šæ ‡æ³¨å­¦ä¹ åˆ°çš„ä½ç½®"""
    # è¯»å–å›¾ç‰‡
    img = cv2.imread(str(img_path))
    if img is None:
        return None
    
    # è·å–å›¾ç‰‡å°ºå¯¸
    img_height, img_width = img.shape[:2]
    print(f"  å›¾ç‰‡å°ºå¯¸: {img_width}x{img_height}")
    
    annotated = False
    
    # æ ‡æ³¨æŒ‰é’®ä½ç½®
    global_file = Path("runtime_data/button_positions/global.json")
    if global_file.exists():
        with open(global_file, 'r', encoding='utf-8') as f:
            button_data = json.load(f)
        
        print(f"  æŒ‰é’®æ•°æ®: {list(button_data.keys())}")
        
        for button_name in button_data.keys():
            best_pos = button_learner.get_best_position(button_name, min_samples=5)
            if best_pos:
                # æ£€æŸ¥åæ ‡æ˜¯å¦åœ¨å›¾ç‰‡èŒƒå›´å†…
                if 0 <= best_pos[0] < img_width and 0 <= best_pos[1] < img_height:
                    stats = button_learner.get_statistics(button_name)
                    draw_button_position(img, button_name, best_pos, stats)
                    print(f"    âœ“ æ ‡æ³¨æŒ‰é’®: {button_name} at ({best_pos[0]}, {best_pos[1]})")
                    annotated = True
                else:
                    print(f"    âœ— è·³è¿‡æŒ‰é’®: {button_name} - åæ ‡è¶…å‡ºèŒƒå›´ ({best_pos[0]}, {best_pos[1]})")
    
    # æ ‡æ³¨OCRåŒºåŸŸ
    global_file = Path("runtime_data/ocr_regions/global.json")
    if global_file.exists():
        with open(global_file, 'r', encoding='utf-8') as f:
            ocr_data = json.load(f)
        
        print(f"  OCRåŒºåŸŸæ•°æ®: {list(ocr_data.keys())}")
        
        for region_name in ocr_data.keys():
            best_region = ocr_learner.get_best_region(region_name, min_samples=5)
            if best_region:
                x, y, w, h = best_region
                # æ£€æŸ¥åŒºåŸŸæ˜¯å¦åœ¨å›¾ç‰‡èŒƒå›´å†…
                if 0 <= x < img_width and 0 <= y < img_height and x + w <= img_width and y + h <= img_height:
                    stats = ocr_learner.get_statistics(region_name)
                    draw_ocr_region(img, region_name, best_region, stats)
                    print(f"    âœ“ æ ‡æ³¨åŒºåŸŸ: {region_name} at ({x}, {y}, {w}, {h})")
                    annotated = True
                else:
                    print(f"    âœ— è·³è¿‡åŒºåŸŸ: {region_name} - åæ ‡è¶…å‡ºèŒƒå›´ ({x}, {y}, {w}, {h})")
    
    return img if annotated else None

def main():
    print("\nåœ¨å®é™…æˆªå›¾ä¸Šæ ‡æ³¨å­¦ä¹ å™¨æ¨èçš„ä½ç½®")
    print("=" * 60)
    
    # åˆå§‹åŒ–å­¦ä¹ å™¨
    button_learner = ButtonPositionLearner()
    ocr_learner = OCRRegionLearner()
    
    # æŸ¥æ‰¾æˆªå›¾
    print("\næ­£åœ¨æŸ¥æ‰¾æˆªå›¾...")
    screenshots = find_latest_screenshots()
    
    if not screenshots:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æˆªå›¾æ–‡ä»¶")
        print("è¯·ç¡®ä¿ä»¥ä¸‹ç›®å½•å­˜åœ¨æˆªå›¾ï¼š")
        print("  - checkin_screenshots/")
        print("  - screenshots/checkin/")
        print("  - screenshots/exception/")
        return
    
    print(f"æ‰¾åˆ° {len(screenshots)} å¼ æˆªå›¾ï¼Œæ­£åœ¨æ ‡æ³¨...")
    
    # æ ‡æ³¨æˆªå›¾
    annotated_count = 0
    for i, img_path in enumerate(screenshots, 1):
        print(f"\n[{i}/{len(screenshots)}] å¤„ç†: {img_path.name}")
        
        annotated_img = annotate_screenshot(img_path, button_learner, ocr_learner)
        
        if annotated_img is not None:
            # ä¿å­˜æ ‡æ³¨åçš„å›¾ç‰‡
            output_path = output_dir / f"annotated_{img_path.name}"
            cv2.imwrite(str(output_path), annotated_img)
            print(f"  âœ… å·²ä¿å­˜: {output_path.name}")
            annotated_count += 1
        else:
            print(f"  âš ï¸ è·³è¿‡ï¼ˆæ— æ³•æ ‡æ³¨ï¼‰")
    
    print("\n" + "=" * 60)
    print(f"âœ… å®Œæˆï¼å…±æ ‡æ³¨ {annotated_count} å¼ å›¾ç‰‡")
    print(f"ğŸ“ æ ‡æ³¨å›¾ç‰‡ä¿å­˜åœ¨: {output_dir.absolute()}")
    
    # æ‰“å¼€æ–‡ä»¶å¤¹
    if annotated_count > 0:
        print("\næ­£åœ¨æ‰“å¼€æ–‡ä»¶å¤¹...")
        import subprocess
        subprocess.run(['explorer', str(output_dir.absolute())])
    
    print("\nå›¾ä¾‹è¯´æ˜ï¼š")
    print("  ğŸ”´ çº¢è‰²åœ†ç‚¹ = æŒ‰é’®æ¨èä½ç½®")
    print("  ğŸŸ¢ ç»¿è‰²çŸ©å½¢ = æŒ‰é’®ä½ç½®æ ‡å‡†å·®èŒƒå›´ï¼ˆ2å€æ ‡å‡†å·®ï¼‰")
    print("  ğŸ”µ è“è‰²çŸ©å½¢ = OCRåŒºåŸŸæ¨èä½ç½®")
    print("=" * 60)

if __name__ == "__main__":
    main()
